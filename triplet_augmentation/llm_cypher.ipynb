{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import os\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import Annoy\n",
    "\n",
    "\n",
    "# from extract_keywords_from_input import extract_keywords_from_input_question\n",
    "\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'sk-'\n",
    "\n",
    "\n",
    "# 1. get the similar entities from the scholar graph\n",
    "def get_similar_entities_in_existing_graph(existing_graph, search_entity, similar_threshold=0.9):\n",
    "    result=existing_graph.similarity_search_with_score(search_entity, k=15)\n",
    "    similar_entities=[]\n",
    "    for res in result:\n",
    "        if res[1]>similar_threshold:\n",
    "            similar_entities.append((res[0].page_content, res[1]))\n",
    "    return similar_entities\n",
    "\n",
    "\n",
    "# get similar entities using HuggingFace BGE model\n",
    "def get_similar_entities(search_entity,entity_list,model_name=\"BAAI/bge-large-en-v1.5\",similar_threshold=0.7):\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    hf = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    # vector_store = Annoy.from_texts(entity_list, hf,n_jobs=3)\n",
    "\n",
    "    embeddings=hf.embed_documents(entity_list)\n",
    "    data=list(zip(entity_list, embeddings))\n",
    "    vector_store = Annoy.from_embeddings(data, hf,n_jobs=3,mertric=\"angular\")\n",
    "    # allows for custom annoy parameters, defaults are n_trees=100, n_jobs=-1, metric=\"angular\"\n",
    "    # vector_store_v2 = Annoy.from_texts(entity_list, hf, metric=\"dot\", n_trees=100, n_jobs=1)\n",
    "\n",
    "    embs=hf.embed_query(search_entity)\n",
    "    result=vector_store.similarity_search_with_score_by_vector(embs, k=100)\n",
    "    # result=vector_store.similarity_search_with_score(search_entity, k=15)\n",
    "    similar_entities=[]\n",
    "    for res in result:\n",
    "        if res[1]<=similar_threshold and (res[0].page_content, res[1]) not in similar_entities:\n",
    "            similar_entities.append((res[0].page_content, res[1]))\n",
    "    return similar_entities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. get the retrieved info from the scholar graph\n",
    "def retrieve_info(existing_graph,similar_entities,retrieval_template):\n",
    "    retrieved_info=[]\n",
    "    for entity in similar_entities:\n",
    "        result=existing_graph.query(retrieval_template.format(entity,entity,entity,entity))\n",
    "        if result:\n",
    "            retrieved_info.extend([val for res in result for _,val in res.items() ])\n",
    "    return set(retrieved_info)\n",
    "\n",
    "\n",
    "\n",
    "# 3. generate the answer based on the input question and retrieved info\n",
    "def generate_answer(question,llm, retrieved_info, answer_template):\n",
    "    prompt = ChatPromptTemplate.from_template(answer_template)\n",
    "    rag_chain = (\n",
    "        {\"context\":  lambda x: retrieved_info,  \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # query = \"the commom methods used in object detection?\"\n",
    "    # query = \"what kind of task include gerneration?\"\n",
    "    answer=rag_chain.invoke(question)\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_knowledgd_from_scholar_graph(input_question,entity_list,existing_graph,retrieval_template,llm,answer_template,similar_threshold=0.9):\n",
    "    # ner_res=extract_keywords_from_input_question(input_question)\n",
    "    ner_res={\"Task\":[\"text-to-image generation\"]} # TODO:需要更换为真实的NER结果\n",
    "    keywords=[k for key,val in ner_res.items() for k in val]\n",
    "    if keywords:\n",
    "        retrived_keywords=[]\n",
    "        print(\"Start to get similar entities...\")\n",
    "        start_time=time.time()\n",
    "        for keyword in keywords:\n",
    "            # similar_entities=get_similar_entities_in_existing_graph(existing_graph, keyword, similar_threshold=0.9)\n",
    "            similar_entities=get_similar_entities(keyword,entity_list)\n",
    "            similar_entities_res=[x[0] for x in similar_entities]\n",
    "            retrived_keywords.extend(similar_entities_res)\n",
    "            print(\"Time used to get similar entities: \",time.time()-start_time)\n",
    "            print(f\"similar entities for {keyword}: {similar_entities_res}\")\n",
    "        \n",
    "    \n",
    "        retrieved_info=retrieve_info(existing_graph,retrived_keywords,retrieval_template)\n",
    "        answer=generate_answer(input_question,llm, retrieved_info, answer_template)\n",
    "    else:\n",
    "        answer=\"No keywords found in the input question.\"\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # TODO：换种方式构建\n",
    "    existing_graph = Neo4jVector.from_existing_index(\n",
    "        embedding=OpenAIEmbeddings(\n",
    "            openai_api_key='hk-',\n",
    "            openai_api_base='https://api.openai-hk.com/v1/'\n",
    "        ),\n",
    "        # embedding=embedding_model,\n",
    "        url = \"\",\n",
    "        username = \"neo4j\",\n",
    "        password = \"baishitong123!\",\n",
    "        index_name='vector',\n",
    "        text_node_property='name',\n",
    "        node_label=[\"Task\"],\n",
    "    )\n",
    "    \n",
    "    retrieval_template='''\n",
    "    OPTIONAL MATCH p=(n1)-[r]-(n2)\n",
    "    WHERE n1.name contains '{}' or n2.name contains '{}'\n",
    "    RETURN\n",
    "    CASE\n",
    "        WHEN n1.name CONTAINS '{}' THEN n1.name +' -> '+type(r)+' -> '+n2.name\n",
    "        WHEN n2.name CONTAINS '{}' THEN n2.name +' -> '+type(r)+' -> '+n1.name\n",
    "    END AS result\n",
    "    '''\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key='',\n",
    "        base_url='http://127.0.0.1:8080/v1',\n",
    "        model='gpt-3.5-turbo',\n",
    "    )\n",
    "\n",
    "    answer_template = \"\"\"\n",
    "    You are an assistant for NER tasks.\n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    entity_df=pd.read_csv(\"data/fused_entity_id_0613_llm.csv\")\n",
    "    entity_list=entity_df[\"entity\"].tolist()\n",
    "\n",
    "    input_question = \"what kind of task include text-to-image generation?\"\n",
    "    answer=retrieve_knowledgd_from_scholar_graph(input_question,entity_list,existing_graph,retrieval_template,llm,answer_template,similar_threshold=0.7)\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate  \n",
    "import pandas as pd\n",
    "import time\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import os\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import Annoy\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "cypher_generation_template = \"\"\"\n",
    "Task:\n",
    "You are a database query operator who needs to extract relevant entities and relationship points from user questions, and construct Cypher statements to query relevant information in the Neo4j graph database.\n",
    "Schema:\n",
    "{schema}  \n",
    "Requirements:\n",
    "The information stored in academic graphs is in English, so the entities extracted from input questions need to be converted to English, consistent with the entities and relationship types defined in the graph.\n",
    "Only use the relationship types and attributes provided in the schema.\n",
    "Do not use any other relationship types or attributes that are not provided.\n",
    "Try to extract potential entities and query targets in the field of artificial intelligence.\n",
    "To avoid missing matches due to case differences, use lowercase for matching uniformly. To ensure the broadness of the query, use fuzzy matching for ambiguous entity names, or match nodes that contain specific keywords.\n",
    "To increase the query hit rate, multiple synonyms can be generated for the extracted entities for joint querying.\n",
    "The returned results must include relevant papers.\n",
    "be careful:\n",
    "Do not include any explanation or apology in your answer.\n",
    "Do not answer any questions that may require you to construct any text other than Cypher statements.\n",
    "Ensure that the relationship direction in the query is correct.\n",
    "Ensure that aliases are set correctly for entities and relationships.\n",
    "Do not run any queries that add or remove content to the database.\n",
    "Make sure to alias all subsequent statements as the 'with' statement.\n",
    "If division is required, make sure to filter the denominator to non-zero values.\n",
    "The input problem is:\n",
    "{question}  \n",
    "\"\"\"\n",
    "\n",
    "qa_generation_template = \"\"\"\n",
    "You are an expert in the field of artificial intelligence, generating reasonable and logically correct academic answers based on user questions and the results of Neo4j Cypher queries.\n",
    "The query results section contains the results of Cypher queries generated based on user natural language questions.\n",
    "The information provided is authoritative, and you must not doubt it or attempt to correct it using internal knowledge.\n",
    "Make the answer sound like an answer to the problem.\n",
    "Query results:\n",
    "{context}  \n",
    "Question:\n",
    "{question}  \n",
    "If the information provided is empty, please answer conservatively, or if it prompts that there is no relevant information in the graph, please re-enter the question.\n",
    "Empty information looks like this: []\n",
    "If the information is not empty, you must use the results to provide an answer, keep the answer concise, do not explain too much, and list the relevant article titles at the end. Remove additional quotes in title list.\n",
    "If the question involves time duration, please assume that the query results are in days unless otherwise specified.\n",
    "Please answer the input questions:\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(  \n",
    "    input_variables=[\"schema\", \"question\"], template=cypher_generation_template\n",
    ")\n",
    "qa_generation_prompt = PromptTemplate(  \n",
    "    input_variables=[\"context\", \"question\"], template=qa_generation_template\n",
    ")  \n",
    "  \n",
    "from langchain_community.graphs import Neo4jGraph  \n",
    "from langchain.chains import GraphCypherQAChain  \n",
    "from langchain_openai import ChatOpenAI  \n",
    " \n",
    "\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"wyf990306\",\n",
    ")\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "\n",
    "\n",
    "gpt_llm = ChatOpenAI(\n",
    "    openai_api_key=\"sk-\",\n",
    "    base_url=\"https://api.openai.com/v1/\",\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "\n",
    "ai_cypher_chain = GraphCypherQAChain.from_llm(   \n",
    "    cypher_llm = gpt_llm,\n",
    "    qa_llm = gpt_llm,\n",
    "    graph=graph,  \n",
    "    verbose=True,  \n",
    "    qa_prompt=qa_generation_prompt,  \n",
    "    cypher_prompt=cypher_generation_prompt,  \n",
    "    validate_cypher=True,  \n",
    "    top_k=100,  \n",
    ")  \n",
    "\n",
    "problem = \"which fields has reinforcement learning been applied to?\"\n",
    "\n",
    "response = ai_cypher_chain.invoke(problem)\n",
    "print(response['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
